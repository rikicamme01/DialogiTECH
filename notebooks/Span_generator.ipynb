{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zbVZweEEW1eD"
   },
   "source": [
    "# Span generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Mhe88vKvVjN5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/Union/Hyperion.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "N1jTvA17WUsV"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "def clean_text(text:str) -> str:\n",
    "    #delete double punctuation\n",
    "    text =  re.sub(r'[\\?\\.\\!]+(?=[\\?\\.\\!])', '', text)\n",
    "    # add space between a word and punctuation\n",
    "    text = re.sub('(?<! )(?=[.,!?()])|(?<=[.,!?()])(?! )', r' ', text)\n",
    "    return text\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for row in df.itertuples():\n",
    "    text = row.Testo\n",
    "    \n",
    "    if pd.isna(text):\n",
    "        sample['Stralci'].append(clean_text(row.Stralcio))\n",
    "        sample['Repertori'].append(row.Repertorio)\n",
    "\n",
    "    else:\n",
    "        sample = {}\n",
    "        sample['Testo'] = clean_text(text)\n",
    "        sample['Stralci'] = [clean_text(row.Stralcio)]\n",
    "\n",
    "        sample['Repertori'] = [row.Repertorio]\n",
    "        dataset.append(sample)\n",
    "\n",
    "\n",
    "\n",
    "#Find bounds starting froma text\n",
    "def find_char_bounds(spans: list, text: str) -> list:\n",
    "    '''\n",
    "    Given a list of spans and a text, find the start and end indices of each span in the text.\n",
    "    Indeces are computed counting CHARS\n",
    "    \n",
    "    :param spans: a list of strings to search for\n",
    "    :type spans: list\n",
    "    :param text: the text to search\n",
    "    :type text: str\n",
    "    :return: A list of tuples, where each tuple contains the start and end index of a span.\n",
    "    '''\n",
    "    start = 0\n",
    "    bounds = []\n",
    "    last_char = -1\n",
    "    for span in spans:\n",
    "        start = text.find(span)\n",
    "        if start == -1:\n",
    "            start = last_char + 1\n",
    "        last_char = start + len(span)\n",
    "        bounds.append((start, last_char))\n",
    "        \n",
    "    return bounds\n",
    "\n",
    "\n",
    "def find_word_bounds(spans: list, text: str) -> list:\n",
    "    '''\n",
    "    Given a list of spans and a text, find the start and end indices of each span in the text.\n",
    "    Indeces are computed counting WORDS.\n",
    "\n",
    "    :param spans: a list of strings, each string is a span of text\n",
    "    :type spans: list\n",
    "    :param text: the text to be searched\n",
    "    :type text: str\n",
    "    :return: A list of tuples, where each tuple is the start and end index of a word in the text.\n",
    "    '''\n",
    "    bounds = []\n",
    "    end = 0\n",
    "    for span in spans:\n",
    "        s = span.translate(str.maketrans('', '', string.punctuation))\n",
    "        word_list = s.split()\n",
    "        text_list = text.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "        try:\n",
    "            start = text_list.index(word_list[0], end)\n",
    "        except:\n",
    "            if not bounds:\n",
    "                start = 0\n",
    "            else:\n",
    "                \n",
    "                start = bounds[-1][1] + 1\n",
    "        end = start + len(word_list) - 1\n",
    "            \n",
    "        bounds.append((start, end))\n",
    "    return bounds\n",
    "\n",
    "def find_segmentation(bounds, text):\n",
    "    text_list = text.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    segmentation = ['0' for i in range(len(text_list))]\n",
    "    segmentation[-1] = '1'\n",
    "    \n",
    "    ends = []\n",
    "    end = 0\n",
    "    for span in spans:\n",
    "        word_list = span.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "        try:\n",
    "            end = text_list.index(word_list[-1], end)\n",
    "        except:\n",
    "                end = end + len(word_list) -1\n",
    "        if end < len(text_list):\n",
    "            ends.append(end)\n",
    "    for i in ends:\n",
    "        segmentation[i] = '1'\n",
    "    \n",
    "    return ''.join(segmentation)\n",
    "\n",
    "def find_segmentation_by_bounds(bounds: list, text: str) -> str:\n",
    "    segmentation = ['0' for i in range(len(text))]\n",
    "    for bound in bounds:\n",
    "        if bound[1] < len(text):\n",
    "            segmentation[bound[1]] = '1'\n",
    "        else:\n",
    "            segmentation[-1] = '1'\n",
    "    return ''.join(segmentation)\n",
    "    \n",
    "    \n",
    "\n",
    "for sample in dataset:\n",
    "    sample['Bounds'] = find_word_bounds(sample['Stralci'], sample['Testo'])\n",
    "    sample['Segmentation'] = find_segmentation_by_bounds(sample['Bounds'], sample['Testo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "x = 0\n",
    "for sample in dataset:\n",
    "    if sample['Bounds'][-1][1] > len(sample['Testo']):\n",
    "        x+=1\n",
    "        #print(sample)\n",
    "        #print(len(sample['Testo']))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lunghezza media stralci:  39.450438147263\n",
      "3179\n"
     ]
    }
   ],
   "source": [
    "mean = 0\n",
    "count = 0\n",
    "max_words = 1\n",
    "for sample in dataset:\n",
    "    for span in sample['Stralci']:\n",
    "        count += 1\n",
    "        word_list = span.split()\n",
    "        mean += len(word_list)\n",
    "        if max_words < len(word_list):\n",
    "            max_words = len(word_list)\n",
    "mean_lenght = mean / count\n",
    "print('Lunghezza media stralci: ', mean_lenght)\n",
    "print(max_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero testi nel dataset 15332\n",
      "Numero span nel dataset: 35148\n",
      "Media span per testo:  2.2924602139316463\n",
      "Massimo numero di span in un singolo testo:  94\n"
     ]
    }
   ],
   "source": [
    "print('Numero testi nel dataset', str(len(dataset)))\n",
    "n_spans = 0\n",
    "for e in dataset:\n",
    "    n_spans += len(e['Bounds'])\n",
    "print('Numero span nel dataset:', str(n_spans)) \n",
    "print('Media span per testo: ', str(n_spans / len(dataset)))\n",
    "maximum = 0\n",
    "max_i = 0\n",
    "for i,e in enumerate(dataset):\n",
    "    if len(e['Bounds']) > maximum:\n",
    "        maximum = len(e['Bounds'])\n",
    "        max_i = i\n",
    "print('Massimo numero di span in un singolo testo: ', str(maximum))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wUofuB4KWhf3",
    "outputId": "95a850fb-aa28-437f-b07f-d256f2fb399e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/michele/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk import sent_tokenize\n",
    "import re\n",
    "\n",
    "nltk_pred = []\n",
    "spans_pred = []\n",
    "\n",
    "for sample in dataset:\n",
    "    spans = sent_tokenize(sample['Testo'])\n",
    "    bounds = []    \n",
    "    #bounds += find_char_bounds([sample['Testo']], sample['Testo'])\n",
    "    bounds += find_word_bounds(spans, sample['Testo'])\n",
    "    nltk_pred.append(bounds)\n",
    "    spans_pred.append(spans) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "r1N5H04_WlbH"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# A è B sono tupe con i bound dello span\n",
    "def IoU(A, B):\n",
    "    if A == B:\n",
    "        return 1\n",
    "    start = max(A[0], B[0])\n",
    "    end = min(A[1], B[1])\n",
    "    if(start > end):\n",
    "        return 0\n",
    "    intersection = end - start\n",
    "    return intersection / (A[1] - A[0] + B[1] - B[0] - intersection)\n",
    "\n",
    "def compute_IoUs(pred_bounds, gt_spans):\n",
    "    \"\"\"\n",
    "    Given a list of predicted spans and a list of ground truth spans, \n",
    "    compute the IoU between each pair of spans\n",
    "    \n",
    "    :param pred_bounds: a tuple of (start, end) denoting the predicted answer\n",
    "    :param gt_spans: a list of tuples of the form (start, end) representing the spans of each ground\n",
    "    truth annotation\n",
    "    :return: a list of IoUs for each ground truth span.\n",
    "    \"\"\"\n",
    "    IoUs = []\n",
    "    for gt_bounds in gt_spans:\n",
    "        IoUs.append(IoU(pred_bounds, gt_bounds)) \n",
    "    return IoUs\n",
    "\n",
    "#Input: text_spans_dict = [ {\n",
    "#           'Bounds' : (a,b), \n",
    "#           'IoU' : float,\n",
    "#           'Repertorio': 'string':\n",
    "#           } ]\n",
    "def normalize(text_spans_dict, gt_spans):\n",
    "    normalized = []\n",
    "    for i in range(len(text_spans_dict)):\n",
    "        #normalized is not empty\n",
    "        if normalized:\n",
    "            if normalized[-1]['Repertorio'] == text_spans_dict[i]['Repertorio']:\n",
    "                new_span = (normalized[-1]['Bounds'][0], text_spans_dict[i]['Bounds'][1])\n",
    "                new_span_features = {\n",
    "                    'Bounds' : new_span, \n",
    "                    'IoU' : None,\n",
    "                    'Repertorio' : text_spans_dict[i]['Repertorio']\n",
    "                    }\n",
    "                del normalized[-1]\n",
    "                normalized.append(new_span_features)\n",
    "            else:\n",
    "                normalized.append(text_spans_dict[i])\n",
    "        else:\n",
    "            normalized.append(text_spans_dict[i])\n",
    "        \n",
    "    \n",
    "    for i in range(len(normalized)):\n",
    "        normalized[i]['IoU'] = max(compute_IoUs(normalized[i]['Bounds'], gt_spans['Bounds']))\n",
    "    return normalized\n",
    "\n",
    "def intersection(A, B):\n",
    "    if A == B:\n",
    "        return 1\n",
    "    start = max(A[0], B[0])\n",
    "    end = min(A[1], B[1])\n",
    "    if(start > end):\n",
    "        return 0\n",
    "    return end - start\n",
    "\n",
    "def normalize_bounds_by_repertoire(bounds, sample):\n",
    "    bounds_w_rep = []\n",
    "    for bound in bounds:\n",
    "        intersections = []\n",
    "        for gt_bound in sample['Bounds']:\n",
    "            intersections.append(intersection(bound, gt_bound))\n",
    "        rep_idx = np.argmax(intersections)\n",
    "        bounds_w_rep.append({\n",
    "            'Bounds': bound,\n",
    "            'Repertorio': sample['Repertori'][rep_idx]\n",
    "            })\n",
    "    normalized = []\n",
    "    for i in range(len(bounds_w_rep)):\n",
    "        #normalized is not empty\n",
    "        if normalized:\n",
    "            if normalized[-1]['Repertorio'] == bounds_w_rep[i]['Repertorio']:\n",
    "                new_span = (normalized[-1]['Bounds'][0], bounds_w_rep[i]['Bounds'][1])\n",
    "                new_span_features = {\n",
    "                    'Bounds' : new_span, \n",
    "                    'Repertorio' : bounds_w_rep[i]['Repertorio']\n",
    "                    }\n",
    "                del normalized[-1]\n",
    "                normalized.append(new_span_features)\n",
    "            else:\n",
    "                normalized.append(bounds_w_rep[i])\n",
    "        else:\n",
    "            normalized.append(bounds_w_rep[i])\n",
    "    return [e['Bounds'] for e in normalized]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.segmentation import windowdiff, ghd, pk\n",
    "\n",
    "met_list = []\n",
    "\n",
    "\n",
    "for i,sample in enumerate(dataset):\n",
    "    seg_pred = find_segmentation_by_bounds(nltk_pred[i], sample['Testo'])\n",
    "    \n",
    "    wd_value = windowdiff(sample['Segmentation'], seg_pred,  6)\n",
    "    \n",
    "    ghd_value = ghd(sample['Segmentation'], seg_pred)\n",
    "    \n",
    "    pk_value = pk(sample['Segmentation'], seg_pred, 6)\n",
    "\n",
    "    text_IoUs = []\n",
    "    for bound in nltk_pred[i]:\n",
    "        IoUs = compute_IoUs(bound, sample['Bounds'])\n",
    "        best = np.argmax(IoUs)\n",
    "        text_IoUs.append(IoUs[best])\n",
    "    \n",
    "    met_dict = {\n",
    "        'windowdiff' : wd_value,\n",
    "        'ghd' : ghd_value,\n",
    "        'pk' : pk_value,\n",
    "        'iou' : text_IoUs\n",
    "        }\n",
    "    met_list.append(met_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_met_list = []\n",
    "norm_span_counter = 0\n",
    "\n",
    "for i,sample in enumerate(dataset):\n",
    "    norm_pred_bounds = normalize_bounds_by_repertoire(nltk_pred[i], sample)\n",
    "    norm_span_counter += len(norm_pred_bounds)\n",
    "\n",
    "    seg_pred = find_segmentation_by_bounds(norm_pred_bounds, sample['Testo'])\n",
    "    \n",
    "    wd_value = windowdiff(sample['Segmentation'], seg_pred,  6)\n",
    "    \n",
    "    ghd_value = ghd(sample['Segmentation'], seg_pred)\n",
    "    \n",
    "    pk_value = pk(sample['Segmentation'], seg_pred, 6)\n",
    "\n",
    "    text_IoUs = []\n",
    "    for bound in norm_pred_bounds:\n",
    "        IoUs = compute_IoUs(bound, sample['Bounds'])\n",
    "        best = np.argmax(IoUs)\n",
    "        text_IoUs.append(IoUs[best])\n",
    "    \n",
    "    norm_met_dict = {\n",
    "        'windowdiff' : wd_value,\n",
    "        'ghd' : ghd_value,\n",
    "        'pk' : pk_value,\n",
    "        'iou' : text_IoUs\n",
    "        }\n",
    "    norm_met_list.append(norm_met_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "Risultati labels GT e stralci non uniti\n",
      "Numero testi nel dataset: 15332\n",
      "Numero stralci nel dataset: 35148\n",
      "Numero stralci predetti: 76323\n",
      "Percentuale span perfetti:  0.15650590254575947\n",
      "Media IoU: 0.33855766320375574\n",
      "Media Windowdiff: 0.03788817805133362\n",
      "Media Pk: 0.03291452704564302\n",
      "Media ghd: 7.290242629793895\n"
     ]
    }
   ],
   "source": [
    "print('----------------------------------------------------------')\n",
    "print('Risultati labels GT e stralci non uniti')\n",
    "\n",
    "print('Numero testi nel dataset:', str(len(dataset)))\n",
    "\n",
    "n_spans = 0\n",
    "for e in dataset:\n",
    "    n_spans += len(e['Bounds'])\n",
    "print('Numero stralci nel dataset:', str(n_spans))\n",
    "\n",
    "n_spans = 0\n",
    "for e in nltk_pred:\n",
    "    n_spans += len(e)\n",
    "print('Numero stralci predetti:', str(n_spans))\n",
    "\n",
    "IoUs = [e['iou'] for e in met_list]\n",
    "flat_IoUs = [item for sublist in IoUs for item in sublist]\n",
    "mean_IoU = np.mean(flat_IoUs)\n",
    "mean_wd = np.mean([e['windowdiff'] for e in met_list])\n",
    "mean_pk = np.mean([e['pk'] for e in met_list])\n",
    "mean_ghd = np.mean([e['ghd'] for e in met_list])\n",
    "\n",
    "perfect_spans = flat_IoUs.count(1)\n",
    "print('Percentuale span perfetti: ', str(perfect_spans / len(flat_IoUs)))\n",
    "\n",
    "print('Media IoU:', str(mean_IoU))\n",
    "print('Media Windowdiff:', str(mean_wd))\n",
    "print('Media Pk:', str(mean_pk))\n",
    "print('Media ghd:', str(mean_ghd))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DBBqubrGWpiv",
    "outputId": "e4aedf5d-7942-4329-9f20-1dcc36da9d0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "Risultati labels GT e stralci uniti\n",
      "Numero testi nel dataset: 15332\n",
      "Numero stralci nel dataset: 35148\n",
      "Numero stralci predetti: 28925\n",
      "Percentuale span perfetti:  0.7330337078651685\n",
      "Media IoU: 0.8884014011915764\n",
      "Media Windowdiff: 0.008931934996139802\n",
      "Media Pk: 0.007766972315728688\n",
      "Media ghd: 1.295982259326898\n"
     ]
    }
   ],
   "source": [
    "print('----------------------------------------------------------')\n",
    "print('Risultati labels GT e stralci uniti')\n",
    "\n",
    "print('Numero testi nel dataset:', str(len(dataset)))\n",
    "\n",
    "n_spans = 0\n",
    "for e in dataset:\n",
    "    n_spans += len(e['Bounds'])\n",
    "print('Numero stralci nel dataset:', str(n_spans))\n",
    "\n",
    "print('Numero stralci predetti:', str(norm_span_counter))\n",
    "\n",
    "IoUs = [e['iou'] for e in norm_met_list]\n",
    "flat_IoUs = [item for sublist in IoUs for item in sublist]\n",
    "mean_IoU = np.mean(flat_IoUs)\n",
    "mean_wd = np.mean([e['windowdiff'] for e in norm_met_list])\n",
    "mean_pk = np.mean([e['pk'] for e in norm_met_list])\n",
    "mean_ghd = np.mean([e['ghd'] for e in norm_met_list])\n",
    "\n",
    "perfect_spans = flat_IoUs.count(1)\n",
    "\n",
    "print('Percentuale span perfetti: ', str(perfect_spans / len(flat_IoUs)))\n",
    "\n",
    "print('Media IoU:', str(mean_IoU))\n",
    "print('Media Windowdiff:', str(mean_wd))\n",
    "print('Media Pk:', str(mean_pk))\n",
    "print('Media ghd:', str(mean_ghd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5MI0-t_EWuaO"
   },
   "source": [
    "# Span classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vqaKAD_5XLro",
    "outputId": "097feac4-1748-44f6-9d1f-13ba15b71084"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/michele/anaconda3/lib/python3.9/site-packages (4.12.5)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (1.20.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (4.62.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (0.2.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (21.0)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: requests in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (2.26.0)\n",
      "Requirement already satisfied: sacremoses in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (2021.8.3)\n",
      "Requirement already satisfied: filelock in /home/michele/anaconda3/lib/python3.9/site-packages (from transformers) (3.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/michele/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /home/michele/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/michele/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/michele/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/michele/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /home/michele/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: click in /home/michele/anaconda3/lib/python3.9/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in /home/michele/anaconda3/lib/python3.9/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: six in /home/michele/anaconda3/lib/python3.9/site-packages (from sacremoses->transformers) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "XwKUZkrBWydE"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained('MiBo/RepML')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-italian-xxl-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZFjoRPxdXZ1a",
    "outputId": "f5cfd1bb-63c8-449c-ec1d-67765c189645"
   },
   "outputs": [],
   "source": [
    "predicted_dataset = []\n",
    "\n",
    "for i, span_group in enumerate(spans_pred):\n",
    "  text_features = {}\n",
    "  text_features['Testo'] = dataset[i]['Testo']\n",
    "  text_features['Stralci'] = [span.lower() for span in span_group]\n",
    "  text_features['Bounds'] = nltk_pred[i]\n",
    "  text_features['Segmentation'] = find_segmentation_by_bounds(nltk_pred[i], dataset[i]['Testo'])\n",
    "  predicted_dataset.append(text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero testi nel dataset 15572\n",
      "Numero span nel dataset: 64447\n",
      "Media span per testo:  4.138646288209607\n",
      "Massimo numero di span in un singolo testo:  126\n"
     ]
    }
   ],
   "source": [
    "print('Numero testi nel dataset', str(len(dataset)))\n",
    "n_spans = 0\n",
    "for e in predicted_dataset:\n",
    "    n_spans += len(e['Bounds'])\n",
    "print('Numero span nel dataset:', str(n_spans))\n",
    "print('Media span per testo: ', str(n_spans / len(predicted_dataset)))\n",
    "maximum = 0\n",
    "max_i = 0\n",
    "for i,e in enumerate(predicted_dataset):\n",
    "    if len(e['Bounds']) > maximum:\n",
    "        maximum = len(e['Bounds'])\n",
    "        max_i = i\n",
    "print('Massimo numero di span in un singolo testo: ', str(maximum))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.588042640637041"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "55873 / 15572"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "oLXXkBsRoh8I"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn import preprocessing\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "LABELS = [\n",
    "                'anticipazione',\n",
    "                'causa',\n",
    "                'commento',\n",
    "                'conferma',\n",
    "                'considerazione',\n",
    "                'contrapposizione',\n",
    "                'deresponsabilizzazione',\n",
    "                'descrizione',\n",
    "                'dichiarazione di intenti',\n",
    "                'generalizzazione',\n",
    "                'giudizio',\n",
    "                'giustificazione',\n",
    "                'implicazione',\n",
    "                'non risposta',\n",
    "                'opinione',\n",
    "                'possibilità',\n",
    "                'prescrizione',\n",
    "                'previsione',\n",
    "                'proposta',\n",
    "                'ridimensionamento',\n",
    "                'sancire',\n",
    "                'specificazione',\n",
    "                'valutazione'\n",
    "        ]\n",
    "\n",
    "\n",
    "def decode_labels(encoded_labels):\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(LABELS)\n",
    "    return le.inverse_transform(encoded_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "04313pMw4p4Y"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import utils\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def predict_labels(text: dict)-> list:\n",
    "  pred = []\n",
    "  if text['Stralci']:\n",
    "    encodings = tokenizer(\n",
    "          text['Stralci'],\n",
    "          max_length=512,\n",
    "          add_special_tokens=True,\n",
    "          return_attention_mask=True,\n",
    "          padding=True,\n",
    "          truncation=True,\n",
    "          return_tensors=\"pt\"\n",
    "      )\n",
    "      \n",
    "  test_dataset = TensorDataset(encodings['input_ids'],encodings['attention_mask'])\n",
    "  test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    " \n",
    "  for i, batch in enumerate(test_dataloader):\n",
    "      b_input_ids = batch[0].to(device)\n",
    "      b_input_mask = batch[1].to(device)\n",
    "      with torch.no_grad():        \n",
    "\n",
    "          # Forward pass, calculate logits\n",
    "          # argmax(logits) = argmax(Softmax(logits))\n",
    "          outputs = model(b_input_ids, \n",
    "                                  attention_mask=b_input_mask)\n",
    "          logits = outputs[0]\n",
    "\n",
    "      logits = logits.detach().cpu()\n",
    "\n",
    "      batch_pred = logits.softmax(dim=1)\n",
    "      pred += batch_pred.argmax(dim=1)\n",
    "  return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "vPf_u-IK73wQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testo:  0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_160369/3555640013.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mrep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecode_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0mpredicted_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Repertori'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mrep\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_160369/513660088.py\u001b[0m in \u001b[0;36mpredict_labels\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     28\u001b[0m           \u001b[0;31m# Forward pass, calculate logits\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m           \u001b[0;31m# argmax(logits) = argmax(Softmax(logits))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m           outputs = model(b_input_ids, \n\u001b[0m\u001b[1;32m     31\u001b[0m                                   attention_mask=b_input_mask)\n\u001b[1;32m     32\u001b[0m           \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1528\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1530\u001b[0;31m         outputs = self.bert(\n\u001b[0m\u001b[1;32m   1531\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1532\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    994\u001b[0m             \u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpast_key_values_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    995\u001b[0m         )\n\u001b[0;32m--> 996\u001b[0;31m         encoder_outputs = self.encoder(\n\u001b[0m\u001b[1;32m    997\u001b[0m             \u001b[0membedding_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    998\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    581\u001b[0m                 )\n\u001b[1;32m    582\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    584\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0;31m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0mself_attn_past_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpast_key_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         self_attention_outputs = self.attention(\n\u001b[0m\u001b[1;32m    471\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    398\u001b[0m         \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m     ):\n\u001b[0;32m--> 400\u001b[0;31m         self_outputs = self.self(\n\u001b[0m\u001b[1;32m    401\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    286\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpast_key_value\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_layer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mkey_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m             \u001b[0mvalue_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mtranspose_for_scores\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_decoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_decoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose_for_scores\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m         \u001b[0mnew_x_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_attention_heads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention_head_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnew_x_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Setup for testing with gpu\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "for i, text in enumerate(predicted_dataset):\n",
    "  pred = predict_labels(text)\n",
    "  rep = decode_labels(list(pred))\n",
    "  predicted_dataset[i]['Repertori'] =rep\n",
    "\n",
    "  if i%100==0:\n",
    "    print('testo: ', str(i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "cHXeeghItQUW",
    "outputId": "b38040ee-de4d-481a-d2a9-f50431a6a27f"
   },
   "outputs": [],
   "source": [
    "norm_met_list = []\n",
    "norm_span_counter = 0\n",
    "\n",
    "for i,sample in enumerate(predicted_dataset):\n",
    "    norm_pred_bounds = normalize_bounds_by_repertoire(nltk_pred[i], sample)\n",
    "    norm_span_counter += len(norm_pred_bounds)\n",
    "\n",
    "    seg_pred = find_segmentation_by_bounds(norm_pred_bounds, sample['Testo'])\n",
    "    \n",
    "    wd_value = windowdiff(dataset[i]['Segmentation'], seg_pred,  6)\n",
    "    \n",
    "    ghd_value = ghd(dataset[i]['Segmentation'], seg_pred)\n",
    "    \n",
    "    pk_value = pk(dataset[i]['Segmentation'], seg_pred, 6)\n",
    "\n",
    "    text_IoUs = []\n",
    "    for bound in norm_pred_bounds:\n",
    "        IoUs = compute_IoUs(bound, dataset[i]['Bounds'])\n",
    "        best = np.argmax(IoUs)\n",
    "        text_IoUs.append(IoUs[best])\n",
    "    \n",
    "    norm_met_dict = {\n",
    "        'windowdiff' : wd_value,\n",
    "        'ghd' : ghd_value,\n",
    "        'pk' : pk_value,\n",
    "        'iou' : text_IoUs\n",
    "        }\n",
    "    norm_met_list.append(norm_met_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('----------------------------------------------------------')\n",
    "print('Risultati labels GT e stralci uniti')\n",
    "\n",
    "print('Numero testi nel dataset:', str(len(dataset)))\n",
    "\n",
    "n_spans = 0\n",
    "for e in dataset:\n",
    "    n_spans += len(e['Bounds'])\n",
    "print('Numero stralci nel dataset:', str(n_spans))\n",
    "\n",
    "print('Numero stralci predetti:', str(norm_span_counter))\n",
    "\n",
    "IoUs = [e['iou'] for e in norm_met_list]\n",
    "flat_IoUs = [item for sublist in IoUs for item in sublist]\n",
    "mean_IoU = np.mean(flat_IoUs)\n",
    "mean_wd = np.mean([e['windowdiff'] for e in norm_met_list])\n",
    "mean_pk = np.mean([e['pk'] for e in norm_met_list])\n",
    "mean_ghd = np.mean([e['ghd'] for e in norm_met_list])\n",
    "\n",
    "perfect_spans = flat_IoUs.count(1)\n",
    "\n",
    "print('Percentuale span perfetti: ', str(perfect_spans / len(flat_IoUs)))\n",
    "\n",
    "print('Media IoU:', str(mean_IoU))\n",
    "print('Media Windowdiff:', str(mean_wd))\n",
    "print('Media Pk:', str(mean_pk))\n",
    "print('Media ghd:', str(mean_ghd))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Span_generator.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "925faa4ca74e07e17e8807425b2222c7f6b32ec00bddad3c89cd83a7cae0c688"
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
