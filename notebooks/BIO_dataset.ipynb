{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('../data/Union/Hyperion.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "#Find bounds starting froma text\n",
    "def find_char_bounds(spans: list, text: str) -> list:\n",
    "    '''\n",
    "    Given a list of spans and a text, find the start and end indices of each span in the text.\n",
    "    Indeces are computed counting CHARS\n",
    "    \n",
    "    :param spans: a list of strings to search for\n",
    "    :type spans: list\n",
    "    :param text: the text to search\n",
    "    :type text: str\n",
    "    :return: A list of tuples, where each tuple contains the start and end index of a span.\n",
    "    '''\n",
    "    start = 0\n",
    "    bounds = []\n",
    "    last_char = -1\n",
    "    for span in spans:\n",
    "        start = text.find(span)\n",
    "        if start == -1:\n",
    "            start = last_char + 1\n",
    "        last_char = start + len(span)\n",
    "        bounds.append((start, last_char))\n",
    "        \n",
    "    return bounds\n",
    "\n",
    "\n",
    "def find_word_bounds(spans: list, text: str) -> list:\n",
    "    '''\n",
    "    Given a list of spans and a text, find the start and end indices of each span in the text.\n",
    "    Indeces are computed counting WORDS.\n",
    "\n",
    "    :param spans: a list of strings, each string is a span of text\n",
    "    :type spans: list\n",
    "    :param text: the text to be searched\n",
    "    :type text: str\n",
    "    :return: A list of tuples, where each tuple is the start and end index of a word in the text.\n",
    "    '''\n",
    "    bounds = []\n",
    "    end = 0\n",
    "    for span in spans:\n",
    "        s = span.translate(str.maketrans('', '', string.punctuation))\n",
    "        word_list = s.split()\n",
    "        if word_list:   \n",
    "            text_list = text.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "            try:\n",
    "                start = text_list.index(word_list[0], end)\n",
    "            except:\n",
    "                if not bounds:\n",
    "                    start = 0\n",
    "                else:\n",
    "\n",
    "                    start = bounds[-1][1] + 1\n",
    "            end = start + len(word_list) - 1\n",
    "\n",
    "            bounds.append((start, end))\n",
    "    return bounds\n",
    "\n",
    "def find_segmentation(bounds, text):\n",
    "    text_list = text.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "    segmentation = ['0' for i in range(len(text_list))]\n",
    "    segmentation[-1] = '1'\n",
    "    \n",
    "    ends = []\n",
    "    end = 0\n",
    "    for span in spans:\n",
    "        word_list = span.translate(str.maketrans('', '', string.punctuation)).split()\n",
    "        try:\n",
    "            end = text_list.index(word_list[-1], end)\n",
    "        except:\n",
    "                end = end + len(word_list) -1\n",
    "        if end < len(text_list):\n",
    "            ends.append(end)\n",
    "    for i in ends:\n",
    "        segmentation[i] = '1'\n",
    "    \n",
    "    return ''.join(segmentation)\n",
    "\n",
    "def find_segmentation_by_bounds(bounds: list) -> str:\n",
    "    segmentation = ['0' for i in range(bounds[-1][1] + 1)]\n",
    "    for bound in bounds:\n",
    "        if bound[1] < len(segmentation):\n",
    "            segmentation[bound[1]] = '1'\n",
    "    segmentation[-1] = '1'\n",
    "    return ''.join(segmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "import re\n",
    "\n",
    "def clean_text(text:str) -> str:\n",
    "    #delete \\n\n",
    "    text = text.replace('\\n', ' ')\n",
    "    #delete double punctuation\n",
    "    text =  re.sub(r'[\\?\\.\\!]+(?=[\\?\\.\\!])', '', text)\n",
    "    # add space between a word and punctuation\n",
    "    text = re.sub('(?<! )(?=[.,!?()])|(?<=[.,!?()])(?! )', r' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "dataset = []\n",
    "\n",
    "for row in df.itertuples():\n",
    "    text = row.Testo\n",
    "    \n",
    "    if pd.isna(text):\n",
    "        sample['Stralci'].append(clean_text(row.Stralcio))\n",
    "        sample['Repertori'].append(row.Repertorio)\n",
    "\n",
    "    else:\n",
    "        sample = {}\n",
    "        sample['Testo'] = clean_text(text)\n",
    "        sample['Stralci'] = [clean_text(row.Stralcio)]\n",
    "\n",
    "        sample['Repertori'] = [row.Repertorio]\n",
    "        dataset.append(sample)\n",
    "\n",
    "\n",
    "for sample in dataset:\n",
    "    sample['Char_Bounds'] = find_char_bounds(sample['Stralci'], sample['Testo'])\n",
    "    sample['Bounds'] = find_word_bounds(sample['Stralci'], sample['Testo'])\n",
    "    sample['Char_Segmentation'] = find_segmentation_by_bounds(sample['Char_Bounds'])\n",
    "    sample['Segmentation'] = find_segmentation_by_bounds(sample['Bounds'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "IE_dict = {\n",
    "    'Testo': [sample['Testo'] for sample in dataset],\n",
    "    'Char_Segmentation': [sample['Char_Segmentation'] for sample in dataset],\n",
    "    'Segmentation': [sample['Segmentation'] for sample in dataset],\n",
    "    'Bounds': [sample['Bounds'] for sample in dataset],\n",
    "    'Char_Bounds': [sample['Char_Bounds'] for sample in dataset],\n",
    "    'Repertori': [sample['Repertori'] for sample in dataset],\n",
    "    'Stralci': [sample['Stralci'] for sample in dataset]\n",
    "}\n",
    "IE_df = pd.DataFrame(IE_dict)\n",
    "IE_df = IE_df.head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "class IE_Hyperion_dataset(Dataset):\n",
    "    def __init__(self, df, tokenizer_name):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        self.df = df\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.df['Testo'].iloc[idx]\n",
    "        encoding = self.tokenizer(text,\n",
    "                                  # is_pretokenized=True,\n",
    "                                  return_special_tokens_mask=True,\n",
    "                                  return_offsets_mapping=True,\n",
    "                                  add_special_tokens=True,\n",
    "                                  return_attention_mask=True,\n",
    "                                  padding='max_length',\n",
    "                                  truncation=True,\n",
    "                                  )\n",
    "        char_labels = list(self.df['Char_Segmentation'].iloc[idx])\n",
    "        ends = [i for i in range(len(char_labels)) if char_labels[i] == '1']\n",
    "\n",
    "        last_token_idx = max(index for index, item in enumerate(encoding['special_tokens_mask']) if item == 0)\n",
    "\n",
    "        encoded_labels = np.ones(len(encoding['input_ids']), dtype=int) * -100\n",
    "        x = ends.pop(0)\n",
    "        for i,e in enumerate(encoding['offset_mapping']):\n",
    "            if e[1] != 0:\n",
    "                # overwrite label\n",
    "                if x >= e[0] and x <= e[1]:# Doubt if insert < e[1] because of offset mapping composition\n",
    "                    encoded_labels[i] = 1\n",
    "                    if ends: \n",
    "                        x = ends.pop(0)\n",
    "                    else:\n",
    "                        x = -1\n",
    "                else:\n",
    "                    encoded_labels[i] = 0\n",
    "\n",
    "        encoded_labels[last_token_idx] = 1\n",
    "\n",
    "\n",
    "        item = {key: torch.as_tensor(val) for key, val in encoding.items()}\n",
    "        item['labels'] = torch.as_tensor(encoded_labels)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FULL Dataset: (100, 7)\n",
      "TRAIN Dataset: (64, 7)\n",
      "VALIDATION Dataset: (16, 7)\n",
      "TEST Dataset: (20, 7)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"dbmdz/bert-base-italian-xxl-uncased\"\n",
    "train_size = 0.8\n",
    "train_df = IE_df.sample(frac=train_size, random_state=200)\n",
    "test_df = IE_df.drop(train_df.index).reset_index(drop=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "val_size = 0.2\n",
    "val_df = train_df.sample(frac=val_size, random_state=200)\n",
    "train_df = train_df.drop(val_df.index).reset_index(drop=True)\n",
    "train_df = train_df.reset_index(drop=True)\n",
    "\n",
    "print(\"FULL Dataset: {}\".format(IE_df.shape))\n",
    "print(\"TRAIN Dataset: {}\".format(train_df.shape))\n",
    "print(\"VALIDATION Dataset: {}\".format(val_df.shape))\n",
    "print(\"TEST Dataset: {}\".format(test_df.shape))\n",
    "\n",
    "train_dataset = IE_Hyperion_dataset(train_df, model_name)\n",
    "val_dataset = IE_Hyperion_dataset(val_df, model_name)\n",
    "test_dataset = IE_Hyperion_dataset(test_df, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: string series 'monitoring/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.\n",
      "Warning: string series 'monitoring/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.\n",
      "Warning: string series 'monitoring/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.\n",
      "Warning: string series 'monitoring/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.\n",
      "Warning: string series 'monitoring/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.\n",
      "Warning: string series 'monitoring/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.\n",
      "Warning: string series 'monitoring/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.\n",
      "Warning: string series 'monitoring/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.\n",
      "Warning: string series 'monitoring/stdout' value was longer than 1000 characters and was truncated. This warning is printed only once per series.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertForTokenClassification(\n",
      "  (bert): BertModel(\n",
      "    (embeddings): BertEmbeddings(\n",
      "      (word_embeddings): Embedding(32102, 768, padding_idx=0)\n",
      "      (position_embeddings): Embedding(512, 768)\n",
      "      (token_type_embeddings): Embedding(2, 768)\n",
      "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (encoder): BertEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (1): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (2): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (3): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (4): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (5): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (6): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (7): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (8): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (9): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (10): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "        (11): BertLayer(\n",
      "          (attention): BertAttention(\n",
      "            (self): BertSelfAttention(\n",
      "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "            (output): BertSelfOutput(\n",
      "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): BertIntermediate(\n",
      "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          )\n",
      "          (output): BertOutput(\n",
      "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
      "            (dropout): Dropout(p=0.1, inplace=False)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero 1:  187\n",
      "Numero 0:  5352\n",
      "Numero totale token:  5539\n",
      "coeff penalizzazione classe 1: 28.620320855614974\n"
     ]
    }
   ],
   "source": [
    "one_counter = 0\n",
    "zero_counter = 0\n",
    "for e in train_dataset:\n",
    "    for l in e['labels']:\n",
    "        if l == 1:\n",
    "            one_counter += 1\n",
    "        elif l == 0:\n",
    "            zero_counter += 1\n",
    "total = zero_counter + one_counter\n",
    "print('Numero 1: ', str(one_counter))\n",
    "print('Numero 0: ', str(zero_counter))\n",
    "print('Numero totale token: ', str(total))\n",
    "\n",
    "print('coeff penalizzazione classe 1:', str(zero_counter / one_counter))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at dbmdz/bert-base-italian-xxl-uncased were not used when initializing BertForTokenClassification: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at dbmdz/bert-base-italian-xxl-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_name, num_labels=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# Deterministic mode\n",
    "def seed_everything(seed=1464):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "\n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n",
    "\n",
    "\n",
    "def plot_loss(loss, val_loss):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    plt.xticks(range(1, len(loss)+1))\n",
    "    plt.plot(range(1, len(loss)+1), loss, label='train')\n",
    "    plt.plot(range(1, len(val_loss)+1), val_loss, label='val')\n",
    "    plt.title('loss')\n",
    "    plt.legend()\n",
    "    # plt.savefig('loss.png')\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_f1(f1, val_f1):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    plt.xticks(range(1, len(f1)+1))\n",
    "    plt.plot(range(1, len(f1)+1), f1, label='train')\n",
    "    plt.plot(range(1, len(val_f1)+1), val_f1, label='val')\n",
    "    plt.title('f1')\n",
    "    plt.legend()\n",
    "    # plt.savefig('f1.png')\n",
    "    return fig\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(y_true, pred, labels):\n",
    "    fig, ax = plt.subplots(figsize=(20, 20))\n",
    "    disp = ConfusionMatrixDisplay.from_predictions(\n",
    "        y_true, pred, display_labels=labels, normalize='true', values_format='.2f')\n",
    "    disp.plot(cmap=\"Blues\", values_format='.2g',\n",
    "              xticks_rotation='vertical', ax=ax)\n",
    "    return disp.figure_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import neptune.new as neptune\n",
    "\n",
    "\n",
    "class NeptuneLogger():\n",
    "    def __init__(self) -> None:\n",
    "        # Neptune initialization\n",
    "        self.run = neptune.init(\n",
    "            project=\"mibo8/Rep\",\n",
    "            api_token=\"eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vYXBwLm5lcHR1bmUuYWkiLCJhcGlfdXJsIjoiaHR0cHM6Ly9hcHAubmVwdHVuZS5haSIsImFwaV9rZXkiOiJmZmRkYThiZi1mZGNlLTRlMTktODQwNS1hNWFlMWQ2Mjc4N2IifQ==\",\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "from torch.nn import utils\n",
    "\n",
    "import torchmetrics\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AdamW\n",
    "from transformers import get_constant_schedule_with_warmup\n",
    "\n",
    "\n",
    "import neptune.new as neptune\n",
    "\n",
    "\n",
    "class IE_MPTrainer():\n",
    "    def __init__(self, batch_size, lr, n_epochs, loss_fn) -> None:\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = lr\n",
    "        self.n_epochs = n_epochs\n",
    "\n",
    "        self.logger = NeptuneLogger()\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def fit(self, model, train_dataset, val_dataset):\n",
    "        self.logger.run['model'] = model_name\n",
    "\n",
    "        params_info = {\n",
    "            'learning_rate': self.learning_rate,\n",
    "            'batch_size': self.batch_size,\n",
    "            'n_epochs': self.n_epochs\n",
    "        }\n",
    "        #self.logger.run['params'] = params_info\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        # ----------TRAINING\n",
    "\n",
    "        # Measure the total training time for the whole run.\n",
    "        total_t0 = time.time()\n",
    "\n",
    "        epochs_train_loss = []\n",
    "        epochs_val_loss = []\n",
    "\n",
    "        epochs = self.n_epochs\n",
    "\n",
    "        # Creation of Pytorch DataLoaders with shuffle=True for the traing phase\n",
    "        train_dataloader = DataLoader(\n",
    "            train_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "        validation_dataloader = DataLoader(\n",
    "            val_dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "        # Adam algorithm optimized for tranfor architectures\n",
    "        optimizer = AdamW(model.parameters(), lr=self.learning_rate)\n",
    "        #scheduler = get_constant_schedule_with_warmup(optimizer, num_warmup_steps=300)\n",
    "\n",
    "        # Scaler for mixed precision\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "        # Setup for training with gpu\n",
    "        device = torch.device(\n",
    "            'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "        model.to(device)\n",
    "\n",
    "        # For each epoch...\n",
    "        for epoch_i in range(0, epochs):\n",
    "\n",
    "            # ========================================\n",
    "            #               Training\n",
    "            # ========================================\n",
    "\n",
    "            # Perform one full pass over the training set.\n",
    "\n",
    "            print(\"\")\n",
    "            print(\n",
    "                '======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "            print('Training...')\n",
    "\n",
    "            # Measure how long the training epoch takes.\n",
    "            t0 = time.time()\n",
    "\n",
    "            # Reset the total loss for this epoch.\n",
    "            total_train_loss = 0\n",
    "\n",
    "            # Put the model into training mode: Dropout layers are active\n",
    "            model.train()\n",
    "\n",
    "            # For each batch of training data...\n",
    "            for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "                # Progress update every 40 batches.\n",
    "                if step % 10 == 0 and not step == 0:\n",
    "                    # Compute time in minutes.\n",
    "                    elapsed = format_time(time.time() - t0)\n",
    "\n",
    "                    # Report progress.\n",
    "                    print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(\n",
    "                        step, len(train_dataloader), elapsed))\n",
    "\n",
    "                # Unpack this training batch from the dataloader.\n",
    "                #\n",
    "                #  copy each tensor to the GPU using the 'to()' method\n",
    "                #\n",
    "                # 'batch' contains three pytorch tensors:\n",
    "                #   [0]: input ids\n",
    "                #   [1]: attention masks\n",
    "                #   [2]: labels\n",
    "                b_input_ids = batch['input_ids'].to(device)\n",
    "                b_input_mask = batch['attention_mask'].to(device)\n",
    "                b_labels = batch['labels'].to(device)\n",
    "\n",
    "                # clear any previously calculated gradients before performing a\n",
    "                # backward pass\n",
    "                model.zero_grad()\n",
    "\n",
    "                # Perform a forward pass in mixed precision\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    outputs = model(b_input_ids,\n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels)\n",
    "\n",
    "                    #loss = outputs[0]\n",
    "                    \n",
    "                    logits = outputs[1]\n",
    "                    print(logits.size())\n",
    "                    print(b_labels.size())\n",
    "\n",
    "                    #logSoftmax = torch.nn.LogSoftmax(dim=-1)\n",
    "                    loss = self.loss_fn(logits.view(-1, model.num_labels), b_labels.view(-1))\n",
    "\n",
    "                # Move logits and labels to CPU\n",
    "                logits = logits.detach().cpu()\n",
    "                label_ids = b_labels.to('cpu')\n",
    "\n",
    "                # Perform a backward pass to compute the gradients in MIXED precision\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                # Accumulate the training loss over all of the batches so that we can\n",
    "                # calculate the average loss at the end.\n",
    "                total_train_loss += loss.item()\n",
    "\n",
    "                # Unscales the gradients of optimizer's assigned params in-place before the gradient clipping\n",
    "                scaler.unscale_(optimizer)\n",
    "\n",
    "                # Clip the norm of the gradients to 1.0.\n",
    "                # This helps and prevent the \"exploding gradients\" problem.\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "                # Update parameters and take a step using the computed gradient in MIXED precision\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                # scheduler.step()\n",
    "\n",
    "            # Compute the average loss over all of the batches.\n",
    "            avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "            epochs_train_loss.append(avg_train_loss)\n",
    "\n",
    "            # Measure how long this epoch took.\n",
    "            training_time = format_time(time.time() - t0)\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"  Average training loss: {0:.3f}\".format(avg_train_loss))\n",
    "            print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "            # ========================================\n",
    "            #               Validation\n",
    "            # ========================================\n",
    "            # After the completion of each training epoch, measure performance on\n",
    "            # the validation set.\n",
    "\n",
    "            print(\"\")\n",
    "            print(\"Running Validation...\")\n",
    "\n",
    "            t0 = time.time()\n",
    "\n",
    "            # Put the model in evaluation mode: the dropout layers behave differently\n",
    "            model.eval()\n",
    "\n",
    "            total_val_loss = 0\n",
    "\n",
    "            # Evaluate data for one epoch\n",
    "            for batch in validation_dataloader:\n",
    "\n",
    "                # Unpack this training batch from our dataloader.\n",
    "                #\n",
    "                # copy each tensor to the GPU using the 'to()' method\n",
    "                #\n",
    "                # 'batch' contains three pytorch tensors:\n",
    "                #   [0]: input ids\n",
    "                #   [1]: attention masks\n",
    "                #   [2]: labels\n",
    "                b_input_ids = batch['input_ids'].to(device)\n",
    "                b_input_mask = batch['attention_mask'].to(device)\n",
    "                b_labels = batch['labels'].to(device)\n",
    "\n",
    "                # Tell pytorch not to bother with constructing the compute graph during\n",
    "                # the forward pass, since this is only needed for training.\n",
    "                with torch.no_grad():\n",
    "\n",
    "                    # Forward pass, calculate logits\n",
    "                    # argmax(logits) = argmax(Softmax(logits))\n",
    "                    outputs = model(b_input_ids,\n",
    "                                    attention_mask=b_input_mask,\n",
    "                                    labels=b_labels)\n",
    "                    #loss = outputs[0]\n",
    "                    \n",
    "                    logits = outputs[1]\n",
    "\n",
    "                    loss = self.loss_fn(logits.view(-1, model.num_labels), b_labels.view(-1))\n",
    "\n",
    "                # Accumulate the validation loss.\n",
    "                total_val_loss += loss.item()\n",
    "\n",
    "                # Move logits and labels to CPU\n",
    "                logits = logits.detach().cpu()\n",
    "                label_ids = b_labels.to('cpu')\n",
    "\n",
    "            print('VALIDATION: ')\n",
    "\n",
    "            # Compute the average loss over all of the batches.\n",
    "            avg_val_loss = total_val_loss / len(validation_dataloader)\n",
    "            epochs_val_loss.append(avg_val_loss)\n",
    "\n",
    "            # Measure how long the validation run took.\n",
    "            validation_time = format_time(time.time() - t0)\n",
    "\n",
    "            print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "            print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "        loss_fig = plot_loss(epochs_train_loss, epochs_val_loss)\n",
    "\n",
    "        self.logger.run[\"loss\"].upload(neptune.types.File.as_image(loss_fig))\n",
    "        print(\"\")\n",
    "        print(\"Training complete!\")\n",
    "\n",
    "        print(\"Total training took {:} (h:mm:ss)\".format(\n",
    "            format_time(time.time()-total_t0)))\n",
    "\n",
    "    def test(self, model, test_dataset):\n",
    "        # ========================================\n",
    "        #               Test\n",
    "        # ========================================\n",
    "        test_dataloader = DataLoader(\n",
    "            test_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "\n",
    "        # Setup for testing with gpu\n",
    "        device = torch.device(\n",
    "            'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "        print(\"\")\n",
    "        print(\"Running Test...\")\n",
    "        t0 = time.time()\n",
    "\n",
    "        # Save prediction for confusion matrix\n",
    "        preds = []\n",
    "\n",
    "        model.eval()\n",
    "\n",
    "        total_test_loss = 0\n",
    "\n",
    "        # Evaluate data for one epoch\n",
    "        for batch in test_dataloader:\n",
    "            b_input_ids = batch['input_ids'].to(device)\n",
    "            b_input_mask = batch['attention_mask'].to(device)\n",
    "            b_labels = batch['labels'].to(device)\n",
    "            b_special_tokens_mask = batch['special_tokens_mask'].to(device)\n",
    "            with torch.no_grad():\n",
    "\n",
    "                # Forward pass, calculate logits\n",
    "                # argmax(logits) = argmax(Softmax(logits))\n",
    "                outputs = model(b_input_ids,\n",
    "                                attention_mask=b_input_mask,\n",
    "                                labels=b_labels)\n",
    "                #loss = outputs[0]\n",
    "                \n",
    "                logits = outputs[1]\n",
    "                loss = self.loss_fn(logits.view(-1, model.num_labels), b_labels.view(-1))\n",
    "\n",
    "            # Accumulate the test loss.\n",
    "            total_test_loss += loss.item()\n",
    "\n",
    "            # Move logits and labels to CPU\n",
    "            logits = logits.detach().cpu()  # shape (batch_size, seq_len, num_labels\n",
    "            full_probs = logits.softmax(dim=-1)\n",
    "\n",
    "            for i, sample_prob in enumerate(full_probs):\n",
    "                active_prob = []\n",
    "                for j, e in enumerate(b_special_tokens_mask[i]):\n",
    "                    if(e == 0):\n",
    "                        active_prob.append(sample_prob[j].tolist())\n",
    "                preds.append(active_prob)\n",
    "\n",
    "        avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "        #self.logger.run['test/loss'] = avg_test_loss\n",
    "        test_time = format_time(time.time() - t0)\n",
    "\n",
    "        print(\"  Test Loss: {0:.2f}\".format(avg_test_loss))\n",
    "        print(\"  Test took: {:}\".format(test_time))\n",
    "\n",
    "        return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "https://app.neptune.ai/mibo8/Rep/e/REP-308\n",
      "Remember to stop your run once youâ€™ve finished logging your metadata (https://docs.neptune.ai/api-reference/run#.stop). It will be stopped automatically only when the notebook kernel/interactive console is terminated.\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 1e-5\n",
    "batch_size = 3\n",
    "n_epochs = 1\n",
    "class_weights =  [1, 53]\n",
    "trainer = IE_MPTrainer(batch_size, learning_rate, n_epochs, torch.nn.CrossEntropyLoss())\n",
    "#trainer = IE_MPTrainer(batch_size, learning_rate, n_epochs, torch.nn.CrossEntropyLoss(weight = torch.Tensor(class_weights)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michele/miniforge3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "/Users/michele/miniforge3/lib/python3.9/site-packages/torch/cuda/amp/grad_scaler.py:115: UserWarning: torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\n",
      "  warnings.warn(\"torch.cuda.amp.GradScaler is enabled, but CUDA is not available.  Disabling.\")\n",
      "/Users/michele/miniforge3/lib/python3.9/site-packages/torch/autocast_mode.py:141: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 1 ========\n",
      "Training...\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "  Batch    10  of     22.    Elapsed: 0:02:19.\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "  Batch    20  of     22.    Elapsed: 0:04:15.\n",
      "torch.Size([3, 512, 2])\n",
      "torch.Size([3, 512])\n",
      "torch.Size([1, 512, 2])\n",
      "torch.Size([1, 512])\n",
      "\n",
      "  Average training loss: 0.156\n",
      "  Training epoch took: 0:04:31\n",
      "\n",
      "Running Validation...\n",
      "VALIDATION: \n",
      "  Validation Loss: 0.18\n",
      "  Validation took: 0:00:17\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:04:48 (h:mm:ss)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer.fit(model, train_dataset, val_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running Test...\n",
      "tensor([[ 1.0045, -0.7267],\n",
      "        [ 1.9081, -1.9137],\n",
      "        [ 1.3083, -1.4053],\n",
      "        ...,\n",
      "        [ 0.9649, -0.8075],\n",
      "        [ 1.0759, -0.8089],\n",
      "        [ 1.3214, -1.5867]])\n",
      "tensor([[ 1.1609, -0.9291],\n",
      "        [ 2.5817, -2.5536],\n",
      "        [ 2.7970, -3.0996],\n",
      "        ...,\n",
      "        [ 1.5790, -1.2994],\n",
      "        [ 1.5275, -1.4509],\n",
      "        [ 1.6132, -1.8545]])\n",
      "tensor([[ 2.1105, -2.1019],\n",
      "        [ 2.0012, -2.4731],\n",
      "        [ 2.3558, -2.4993],\n",
      "        ...,\n",
      "        [ 1.6499, -1.5646],\n",
      "        [ 1.5525, -1.3145],\n",
      "        [ 1.8178, -2.1608]])\n",
      "tensor([[ 1.3684, -1.0376],\n",
      "        [ 2.4344, -2.1774],\n",
      "        [ 1.9823, -2.0065],\n",
      "        ...,\n",
      "        [ 1.4747, -1.1348],\n",
      "        [ 1.3943, -1.1643],\n",
      "        [ 1.6242, -1.5126]])\n",
      "tensor([[ 1.3154, -1.0624],\n",
      "        [ 1.5849, -1.3825],\n",
      "        [ 1.9746, -2.2241],\n",
      "        ...,\n",
      "        [ 1.8004, -1.3334],\n",
      "        [ 1.6792, -1.3357],\n",
      "        [ 1.7671, -2.1047]])\n",
      "tensor([[ 1.9289, -1.7262],\n",
      "        [ 2.1051, -2.1096],\n",
      "        [ 1.9724, -1.4720],\n",
      "        ...,\n",
      "        [ 1.0107, -1.1104],\n",
      "        [ 1.5798, -1.2594],\n",
      "        [ 1.8298, -1.7595]])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/hn/dgsmw5dx2nddc5dxjt83l9_r0000gn/T/ipykernel_7864/4261712935.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/hn/dgsmw5dx2nddc5dxjt83l9_r0000gn/T/ipykernel_7864/2690288056.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, model, test_dataset)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 \u001b[0mactive_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb_special_tokens_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m                         \u001b[0mactive_prob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_prob\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactive_prob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "probs = trainer.test(model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_segmentation(probs, threshold):  #one sample\n",
    "    if threshold < 0 or threshold > 1:\n",
    "        return None\n",
    "    segmentation = []\n",
    "    for prob in probs:\n",
    "        if prob[1] >= threshold:\n",
    "            segmentation.append(1)\n",
    "        else:\n",
    "            segmentation.append(0)\n",
    "    segmentation[-1] = 1\n",
    "    return segmentation\n",
    "\n",
    "def split_by_prediction(pred:list, input:dict, text:str, tokenizer) -> list:\n",
    "    offset_mapping = input['offset_mapping'].tolist()\n",
    "    i=0\n",
    "    subword_flags = []\n",
    "    while i < len(offset_mapping):\n",
    "        if offset_mapping[i][1] != 0:\n",
    "            if tokenizer.decode(input['input_ids'][i])[:2] == '##':\n",
    "                subword_flags.append(True)\n",
    "            else:\n",
    "                subword_flags.append(False)\n",
    "        i+=1\n",
    "        \n",
    "    for i in range(len(pred)-1):\n",
    "        if pred[i] == 1:\n",
    "            if subword_flags[i + 1]:\n",
    "                pred[i] = 0\n",
    "                pred[i + 1] =1\n",
    "        \n",
    "            \n",
    "    spans = []\n",
    "    start = 0\n",
    "    i=0\n",
    "    while i < len(offset_mapping):\n",
    "        if offset_mapping[i][1] != 0:\n",
    "            x = pred.pop(0)\n",
    "            if x == 1:\n",
    "                spans.append(text[start:offset_mapping[i][1]])\n",
    "                start = offset_mapping[i][1]\n",
    "        i+=1\n",
    "\n",
    "    return spans\n",
    "\n",
    "    #another way to proceed: takes text decoding token_ids\n",
    "    \"\"\"\n",
    "    start = 0\n",
    "    end = 0\n",
    "    spans = []\n",
    "    for i,e in enumerate(pred):\n",
    "        if e == 1:\n",
    "            end = i\n",
    "            span = tokenizer.decode(input['input_ids'][start:end + 1], skip_special_tokens= True, clean_up_tokenization_spaces= False)\n",
    "            spans.append(span)\n",
    "            start = end + 1\n",
    "            end = end + 1\n",
    "    if not spans:\n",
    "        spans.append(tokenizer.decode(input['input_ids'], skip_special_tokens= True, clean_up_tokenization_spaces= False))\n",
    "    return spans\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "preds = [decode_segmentation(e, 0.1) for e in probs]\n",
    "\n",
    "bert_preds = []\n",
    "bert_spans = []\n",
    "for i,e in enumerate(preds):\n",
    "    spans = split_by_prediction(e, test_dataset[i], test_dataset.df.iloc[i]['Testo'], test_dataset.tokenizer)\n",
    "    bert_preds.append(find_word_bounds(spans, test_dataset.df.iloc[i]['Testo']))\n",
    "    bert_spans.append(spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# A Ã¨ B sono tupe con i bound dello span\n",
    "def IoU(A, B):\n",
    "    if A == B:\n",
    "        return 1\n",
    "    start = max(A[0], B[0])\n",
    "    end = min(A[1], B[1])\n",
    "    if(start > end):\n",
    "        return 0\n",
    "    intersection = end - start\n",
    "    return intersection / (A[1] - A[0] + B[1] - B[0] - intersection)\n",
    "\n",
    "def compute_IoUs(pred_bounds, gt_spans):\n",
    "    \"\"\"\n",
    "    Given a list of predicted spans and a list of ground truth spans, \n",
    "    compute the IoU between each pair of spans\n",
    "    \n",
    "    :param pred_bounds: a tuple of (start, end) denoting the predicted answer\n",
    "    :param gt_spans: a list of tuples of the form (start, end) representing the spans of each ground\n",
    "    truth annotation\n",
    "    :return: a list of IoUs for each ground truth span.\n",
    "    \"\"\"\n",
    "    IoUs = []\n",
    "    for gt_bounds in gt_spans:\n",
    "        IoUs.append(IoU(pred_bounds, gt_bounds)) \n",
    "    return IoUs\n",
    "\n",
    "\n",
    "def intersection(A, B):\n",
    "    if A == B:\n",
    "        return 1\n",
    "    start = max(A[0], B[0])\n",
    "    end = min(A[1], B[1])\n",
    "    if(start > end):\n",
    "        return 0\n",
    "    return end - start\n",
    "\n",
    "def normalize_bounds_by_repertoire(bounds, sample):\n",
    "    bounds_w_rep = []\n",
    "    for bound in bounds:\n",
    "        intersections = []\n",
    "        for gt_bound in sample['Bounds']:\n",
    "            intersections.append(intersection(bound, gt_bound))\n",
    "        rep_idx = np.argmax(intersections)\n",
    "        bounds_w_rep.append({\n",
    "            'Bounds': bound,\n",
    "            'Repertorio': sample['Repertori'][rep_idx]\n",
    "            })\n",
    "    normalized = []\n",
    "    for i in range(len(bounds_w_rep)):\n",
    "        #normalized is not empty\n",
    "        if normalized:\n",
    "            if normalized[-1]['Repertorio'] == bounds_w_rep[i]['Repertorio']:\n",
    "                new_span = (normalized[-1]['Bounds'][0], bounds_w_rep[i]['Bounds'][1])\n",
    "                new_span_features = {\n",
    "                    'Bounds' : new_span, \n",
    "                    'Repertorio' : bounds_w_rep[i]['Repertorio']\n",
    "                    }\n",
    "                del normalized[-1]\n",
    "                normalized.append(new_span_features)\n",
    "            else:\n",
    "                normalized.append(bounds_w_rep[i])\n",
    "        else:\n",
    "            normalized.append(bounds_w_rep[i])\n",
    "    return [e['Bounds'] for e in normalized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.metrics.segmentation import windowdiff, ghd, pk\n",
    "\n",
    "met_list = []\n",
    "counter=0\n",
    "\n",
    "for i in range(len(test_dataset.df.index)):\n",
    "    if len(test_dataset.df['Segmentation'].iloc[i]) >= 20:\n",
    "        \n",
    "        \n",
    "        counter += 1\n",
    "        \n",
    "        seg_pred = find_segmentation_by_bounds(bert_preds[i])\n",
    "        seg_pred = seg_pred[:len(test_dataset.df['Segmentation'].iloc[i])]\n",
    "        \n",
    "        seg_gt_trunk = test_dataset.df['Segmentation'].iloc[i][:len(seg_pred)] # manages predictiones in text with n_tokens  > 512\n",
    "        \"\"\"\n",
    "        print(len(test_dataset.df['Segmentation'].iloc[i]))\n",
    "        print(len(seg_pred))\n",
    "        print(test_dataset.df['Testo'].iloc[i])\n",
    "        print('####')\n",
    "        print(test_dataset.df['Stralci'].iloc[i])\n",
    "        print('####')\n",
    "        print(bert_spans[i])\n",
    "        print('----------')\n",
    "        \"\"\"\n",
    "        wd_value = windowdiff(seg_gt_trunk, seg_pred,  20)\n",
    "\n",
    "        ghd_value = ghd(seg_gt_trunk, seg_pred)\n",
    "\n",
    "        pk_value = pk(seg_gt_trunk, seg_pred, 20)\n",
    "\n",
    "        text_IoUs = []\n",
    "        for bound in bert_preds[i]:\n",
    "            IoUs = compute_IoUs(bound, test_dataset.df['Bounds'].iloc[i])\n",
    "            best = np.argmax(IoUs)\n",
    "            text_IoUs.append(IoUs[best])\n",
    "\n",
    "        met_dict = {\n",
    "            'windowdiff' : wd_value,\n",
    "            'ghd' : ghd_value,\n",
    "            'pk' : pk_value,\n",
    "            'iou' : text_IoUs\n",
    "            }\n",
    "        met_list.append(met_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_met_list = []\n",
    "norm_span_counter = 0\n",
    "\n",
    "\n",
    "for i in range(len(test_dataset.df.index)):\n",
    "    if len(test_dataset.df['Segmentation'].iloc[i]) >= 20:\n",
    "        norm_pred_bounds = normalize_bounds_by_repertoire(bert_preds[i], test_dataset.df.iloc[i])\n",
    "        norm_span_counter += len(norm_pred_bounds)\n",
    "\n",
    "        seg_pred = find_segmentation_by_bounds(norm_pred_bounds)\n",
    "        seg_pred = seg_pred[:len(test_dataset.df['Segmentation'].iloc[i])] #artificioso, sarebbe meglio risolvere ed avere le strighe uguali\n",
    "        seg_gt_trunk = test_dataset.df['Segmentation'].iloc[i][:len(seg_pred)] # manages predictiones in text with n_tokens  > 512\n",
    "\n",
    "        wd_value = windowdiff(seg_gt_trunk, seg_pred,  20)\n",
    "\n",
    "        ghd_value = ghd(seg_gt_trunk, seg_pred)\n",
    "\n",
    "        pk_value = pk(seg_gt_trunk, seg_pred, 20)\n",
    "\n",
    "        text_IoUs = []\n",
    "        for bound in norm_pred_bounds:\n",
    "            IoUs = compute_IoUs(bound, test_dataset.df['Bounds'].iloc[i])\n",
    "            best = np.argmax(IoUs)\n",
    "            text_IoUs.append(IoUs[best])\n",
    "\n",
    "        norm_met_dict = {\n",
    "            'windowdiff' : wd_value,\n",
    "            'ghd' : ghd_value,\n",
    "            'pk' : pk_value,\n",
    "            'iou' : text_IoUs\n",
    "            }\n",
    "        norm_met_list.append(norm_met_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "Risultati labels GT e stralci non uniti\n",
      "Numero testi nel dataset: 15332\n",
      "Numero testi cointati nel calcolo metriche (len >= 20) 184\n",
      "Numero stralci nel dataset: 35148\n",
      "Numero stralci predetti: 1132\n",
      "Percentuale span perfetti:  0.05339366515837104\n",
      "Media IoU: 0.42947760030978854\n",
      "Media Windowdiff: 0.5663517756103071\n",
      "Media Pk: 0.33235103671287547\n",
      "Media ghd: 8.668478260869565\n"
     ]
    }
   ],
   "source": [
    "print('----------------------------------------------------------')\n",
    "print('Risultati labels GT e stralci non uniti')\n",
    "\n",
    "print('Numero testi nel dataset:', str(len(dataset)))\n",
    "print('Numero testi cointati nel calcolo metriche (len >= 20)', str(counter))\n",
    "\n",
    "n_spans = 0\n",
    "for e in dataset:\n",
    "    n_spans += len(e['Bounds'])\n",
    "print('Numero stralci nel dataset:', str(n_spans))\n",
    "\n",
    "n_spans = 0\n",
    "for e in bert_preds:\n",
    "    n_spans += len(e)\n",
    "print('Numero stralci predetti:', str(n_spans))\n",
    "\n",
    "IoUs = [e['iou'] for e in met_list]\n",
    "flat_IoUs = [item for sublist in IoUs for item in sublist]\n",
    "mean_IoU = np.mean(flat_IoUs)\n",
    "mean_wd = np.mean([e['windowdiff'] for e in met_list])\n",
    "mean_pk = np.mean([e['pk'] for e in met_list])\n",
    "mean_ghd = np.mean([e['ghd'] for e in met_list])\n",
    "\n",
    "perfect_spans = flat_IoUs.count(1)\n",
    "print('Percentuale span perfetti: ', str(perfect_spans / len(flat_IoUs)))\n",
    "\n",
    "print('Media IoU:', str(mean_IoU))\n",
    "print('Media Windowdiff:', str(mean_wd))\n",
    "print('Media Pk:', str(mean_pk))\n",
    "print('Media ghd:', str(mean_ghd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "Risultati labels GT e stralci uniti\n",
      "Numero testi nel dataset: 15332\n",
      "Numero stralci nel dataset: 35148\n",
      "Numero stralci predetti: 595\n",
      "Percentuale span perfetti:  0.1781512605042017\n",
      "Media IoU: 0.7721682550625731\n",
      "Media Windowdiff: 0.18784616344561764\n",
      "Media Pk: 0.07011654702625082\n",
      "Media ghd: 3.875\n"
     ]
    }
   ],
   "source": [
    "print('----------------------------------------------------------')\n",
    "print('Risultati labels GT e stralci uniti')\n",
    "\n",
    "print('Numero testi nel dataset:', str(len(dataset)))\n",
    "\n",
    "n_spans = 0\n",
    "for e in dataset:\n",
    "    n_spans += len(e['Bounds'])\n",
    "print('Numero stralci nel dataset:', str(n_spans))\n",
    "\n",
    "print('Numero stralci predetti:', str(norm_span_counter))\n",
    "\n",
    "IoUs = [e['iou'] for e in norm_met_list]\n",
    "flat_IoUs = [item for sublist in IoUs for item in sublist]\n",
    "mean_IoU = np.mean(flat_IoUs)\n",
    "mean_wd = np.mean([e['windowdiff'] for e in norm_met_list])\n",
    "mean_pk = np.mean([e['pk'] for e in norm_met_list])\n",
    "mean_ghd = np.mean([e['ghd'] for e in norm_met_list])\n",
    "\n",
    "perfect_spans = flat_IoUs.count(1)\n",
    "\n",
    "print('Percentuale span perfetti: ', str(perfect_spans / len(flat_IoUs)))\n",
    "\n",
    "print('Media IoU:', str(mean_IoU))\n",
    "print('Media Windowdiff:', str(mean_wd))\n",
    "print('Media Pk:', str(mean_pk))\n",
    "print('Media ghd:', str(mean_ghd))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "925faa4ca74e07e17e8807425b2222c7f6b32ec00bddad3c89cd83a7cae0c688"
  },
  "kernelspec": {
   "display_name": "default:Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
